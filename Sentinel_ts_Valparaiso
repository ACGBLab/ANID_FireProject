# This python code is based on Philipp Gärtner Blog. It was revised and adapted by Paula Basualto-Santana and Andrés Plaza-Aguilar
# This python script allow to obtain Sentinel 2 NDVI time series from aleatory points in decimal degree coordinates
# The script use Google Earth Engine API in RStudio. Before run the script it is necessary to create a conda environment with earthengine-api and set up your computer 


import ee      

ee.Initialize() # Initialize the API
print(ee.__version__)


geometry = ee.Geometry.Point(         # Example for one aleatory point from fire fuel category 21 (mixed native forest and wild exotic species, open, semi-dense and dense)
[ -70.82543788,-32.60725752  ]);      # of Valparaíso Region


def maskclouds(image):
    qa = image.select("QA60")
    cloudBitMask  = 1 << 10
    cirrusBitMask = 1 << 11
    mask  = qa.bitwiseAnd(cloudBitMask).eq(0) \
              .And(qa.bitwiseAnd(cirrusBitMask).eq(0))
    return image.updateMask(mask).divide(10000) \
                 .set('date', image.date().format()) # include dates      

### Function to obtain NDVI from Sentinel 2

def ndvi(image):
    ndvi = image.normalizedDifference(["B8","B4"]).rename("ndvi")
    return image.addBands([ndvi])

## Set the dates for the analysis (for the area it is only available from Februrary 2018, however the we set the dates from January 1st 2015)

start_date = ee.Date('2015-01-01')
end_date   = ee.Date('2025-01-31')


## Obtain image collections from Google Earth Engine

s2Sr = ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED") \
         .filterBounds(geometry) \
         .filterDate(start_date, end_date) \
         .filter(ee.Filter.eq('MGRS_TILE', '19HCE')) \
         .map(maskclouds) \
         .map(ndvi)

s2c = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY') \
        .filterBounds(geometry) \
        .filterDate(start_date, end_date);

# The propertyName parameter is the name of the property
# that references the joined image.
def indexJoin(collectionA, collectionB, propertyName):
  joined = ee.ImageCollection(ee.Join.saveFirst(propertyName).apply(
    primary = collectionA,
    secondary = collectionB,
    condition = ee.Filter.equals(
      leftField = 'system:index',
      rightField = 'system:index'
    )
  ))

## Merge the bands of the joined image

  return joined.map(lambda image: image.addBands(ee.Image(image.get(propertyName)).rename("cld")))

## Function to calculate the median values

def calculateMedian(image):
  
  median = image.reduceRegion(reducer  = ee.Reducer.median(),
                            geometry = geometry,
                            scale = 10,
                            maxPixels = 1e9)

## set the recording date and median values as a property of the image
  return image.set('date', image.get('date')).set('median', median)


## Use cloud probability 

withCloudProbability = indexJoin(s2Sr, s2c, 'cloud_probability');

## select only the 'ndvi' and 'cloud probability' values. 
withMedian = withCloudProbability.select(["ndvi","cld"]).map(calculateMedian)

## reduce the images properties to a list of lists
values = withMedian.reduceColumns(ee.Reducer.toList(2), ['date', 'median']).values().get(0)

## Type casts the result into a List
eeList = ee.List(values)

## convert  list of lists to a dictionaty
medians = ee.Dictionary(eeList.flatten())

## Obtain median values
median_values = medians.getInfo(); # ee.Dictionary => Python dictionary
type(median_values)

## Use pandas to export results for R script analysis 
import pandas
pd_df = pandas.DataFrame.from_dict(median_values, orient='index')
pd_df

